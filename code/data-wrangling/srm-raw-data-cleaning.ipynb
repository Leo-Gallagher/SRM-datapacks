{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efac36d",
   "metadata": {},
   "source": [
    "# This Notebook contains the code to filter, clean and manage the SRM raw data output.\n",
    "\n",
    "### The following actions are carried out, please see each section for a more thorough explanation of what occurs\n",
    "\n",
    "#### 0. Import necessary Python modules\n",
    "#### 1. Import Raw Data and Standing data\n",
    "#### 2. Filter out unwanted columns\n",
    "#### 3. Clean dirty columns\n",
    "#### 4. Add new columns that will be used for analysis later on.\n",
    "#### 5. Generate output dataframe and export output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de962448",
   "metadata": {},
   "source": [
    "### 0. Import necesary Python Modules\n",
    "For this project we will manipulate our data using the python library 'Pandas', which requires the use of the library 'NumPy'. These two libraries are imported as 'pd' and 'np' respectively, in line with convention. Additionally we use the datetime module, for superior handling of the dates in our data, and the workdays functions, which contains functions for calculating the differences between two dates without including weekends or holidays (similar to NETWORKDAYS in excel. For further information see here:\n",
    "\n",
    "1. https://numpy.org/doc/stable/\n",
    "2. https://pandas.pydata.org/docs/\n",
    "3. https://docs.python.org/3/library/datetime.html\n",
    "4. https://pypi.org/project/workdays/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25d6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import workdays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1fde56",
   "metadata": {},
   "source": [
    "### 1. Import Raw Data and Standing data\n",
    "We import the raw data from a file which lies OUTSIDE of the repository, as it is too large to be contained on GitHub. As such, please will each user copy the pathname to their raw data.\n",
    "1. LPG pathname: /Users/leogallagher/Documents/FMA-Work/KRG/PFM/Code/Expenditure/raw-data/srm-raw-data\n",
    "\n",
    "There are 5 standing data dataframes in total, 3 of which are necessary to process the raw data. These are:\n",
    "\n",
    "1. standing-data-au-ministry.csv - This associates each accounting unit with a Ministry\n",
    "2. standing-data-current-status.csv - this data associates each of the current status' in the raw data with a status category which is useful to us\n",
    "3. standing-data-ministry-analyst.csv - this identifies which analyst works on which ministry.\n",
    "\n",
    "Each of these must be periodically checked to ensure that the are upto date and are accessible at GitHub at the following address:<br>\n",
    "https://github.com/Leo-Gallagher/SRM-datapacks/tree/main/standing-data\n",
    "\n",
    "If encountering issues with the import of the standing data make sure that the pathname exactly matches that on your local device, and that the file name is exactly correct also.\n",
    "\n",
    "Copy the local pathname root for the standing data here for convenience\n",
    "1. LPG pathname: /Users/leogallagher/Documents/FMA-Work/KRG/PFM/Code/Expenditure/srm-datapack/standing-data/\n",
    "\n",
    "There is also an analysis date that must be UPDATED with the date that the current analysis is being completed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2953e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the root_path\n",
    "root_path = r'/Users/leogallagher/Documents/FMA-Work/KRG/PFM/Code/Expenditure'\n",
    "# Import Raw Data as df\n",
    "df = pd.read_csv(root_path + r'/raw-data/srm-raw-data/230301-srm-raw-data.csv', low_memory=False)\n",
    "\n",
    "#Import Standing data - ***YOU WILL NEED TO USE YOUR OWN PATH NAME***\n",
    "# AU-Ministry Data\n",
    "au_ministry_data = pd.read_csv(root_path + r'/srm-datapack/standing-data/standing-data-au-ministry.csv')\n",
    "\n",
    "# Current Status data\n",
    "current_status = pd.read_csv(root_path + r'/srm-datapack/standing-data/standing-data-current-status.csv')\n",
    "\n",
    "# Ministry/Analyst Data\n",
    "ministry_analyst_data = pd.read_csv(root_path + r'/srm-datapack/standing-data/standing-data-ministry-analyst.csv')\n",
    "\n",
    "# KRG Holiday Data\n",
    "krg_holidays = pd.read_csv(root_path + r'/srm-datapack/standing-data/standing-data-krg-holidays.csv')\n",
    "# we will also need a list of these dates in the datetime format:\n",
    "holiday_dates = pd.to_datetime(krg_holidays['holiday_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbfaae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis date - *** To be updated each time this analysis is done. The format is (YYYY, (M)M, (D)D)\n",
    "analysis_date = datetime(2023, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7266cdc2",
   "metadata": {},
   "source": [
    "### 2. Filter out unwanted columns\n",
    "\n",
    "Here we filter out most of the colums from the raw data as they are not necessary. The list provided in the code can be amended to include or remove columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3c9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep immediately, filtering out the many columns that are unneeded in the raw data\n",
    "df_columns_to_keep = [\n",
    "        'Srid','Date Submitted To Mofe','Approval Number Issued At','Ministry Input Id Issued At',\n",
    "        'Ministry Id Issued At','Ministry Diwan Reviewer Action Date','Ministry Diwan Decision Maker Action Date',\n",
    "        'Entity','Account Code','Exchange Rate','Total Cost Of Line','Amended Total Cost Of Line',\n",
    "        'Savings Of Line','Total Sr Savings','Spending Team Action','Spending Team Action Date',\n",
    "        'Price Evaluation Action','Price Evaluation Action Date','Engineering Directorate Action',\n",
    "        'Engineering Directorate Action Date','Publications Directorate Action',\n",
    "        'Publications Directorate Action Date','Director Of Spending Action','Director Of Spending Action Date',\n",
    "        'Dg Pa Action','Dg Pa Action Date','Minister Of Finance Action','Minister Of Finance Action Date',\n",
    "        'Com Action','Com Action Date', 'Second Round Ministry Diwan Reviewer Action Date',\n",
    "        'Second Round Ministry Diwan Decision Maker Action Date','Second Round Spending Team Action Date',\n",
    "        'Second Round Director Of Spending Action Date','Second Round Dg Pa Action Date',\n",
    "        'Second Round Minister Of Finance Action Date','Second Round Com Action Date',\n",
    "        'Second Round Final Approval Date','Final Approval Date','Current State']\n",
    "df_filtered = df.loc[:, df_columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3455da",
   "metadata": {},
   "source": [
    "### 3. Clean dirty columns (*** CHECK THIS SECTION IS CORRECT***)\n",
    "Many of the columns have messy data in. A list of the cleaning processes is provided here:\n",
    "1. 'Current State' Column - some of the entries are succeeded by a string of the form ' $XXXX', where the X's are placeholders for numbers. Theses elements of the string are removed.\n",
    "2. Various Date Columns - these are cleaned to convert the date into a datetime format and to make sure that missing dates are appropriately marked.<br> \n",
    "    • Most missing dates are tagged with a '-' <br>\n",
    "    • Some are simply missing and are marked as NaN.\n",
    "\n",
    "3. Various Financial Columns: Data in some of the financial columns is missing, either as NaN or '-'. These are replaced (*** Check this is correct***). this applies to the following columns:<br>\n",
    "    • 'Savings Of Line'\n",
    "    • 'Amended Total Cost Of Line'<br>\n",
    "    • 'Total Cost Of Line'>\n",
    "    • 'Exchange Rate'<br>\n",
    "After replacing missing data these are all converted to floats from strings so that we can perform numerical calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d826d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current State Column: Remove characters preceded by a dollar sign from the strings in the Current State column.\n",
    "df_filtered['Current State'] = df_filtered['Current State'].apply(lambda string: string.split(' $')[0])\n",
    "\n",
    "\n",
    "\n",
    "# Date Columns: Format as datetime and deal with any missing values\n",
    "# First define a list of the columns which include dates\n",
    "date_cols = [\n",
    "        'Date Submitted To Mofe','Approval Number Issued At','Ministry Input Id Issued At',\n",
    "        'Ministry Id Issued At','Ministry Diwan Reviewer Action Date',\n",
    "        'Ministry Diwan Decision Maker Action Date','Spending Team Action Date',\n",
    "        'Price Evaluation Action Date','Engineering Directorate Action Date',\n",
    "        'Publications Directorate Action Date','Director Of Spending Action Date',\n",
    "        'Dg Pa Action Date', 'Minister Of Finance Action Date','Com Action Date',\n",
    "        'Second Round Ministry Diwan Reviewer Action Date',\n",
    "        'Second Round Ministry Diwan Decision Maker Action Date',\n",
    "        'Second Round Spending Team Action Date',\n",
    "        'Second Round Director Of Spending Action Date',\n",
    "        'Second Round Dg Pa Action Date',\n",
    "        'Second Round Minister Of Finance Action Date',\n",
    "        'Second Round Com Action Date',\n",
    "        'Second Round Final Approval Date','Final Approval Date']\n",
    "\n",
    "# Loop through the relevant columns converting to datetime. This method also converts not date formats to the\n",
    "# NaT (Not a Time) python generic time NA value. NOTE THAT THIS LOSES THE DIFFERENTATION BETWEEN ABSENT TIMES\n",
    "# THAT WERE '-' AND WERE ORGINALLY NaN. \n",
    "for col in date_cols:\n",
    "    df_filtered[col] = pd.to_datetime(df_filtered[col], \n",
    "                                      format='%Y-%m-%d %I:%M %p',\n",
    "                                      errors='coerce').fillna(pd.NaT)\n",
    "    \n",
    "\n",
    "    \n",
    "# Financial Columns: First define the columns to process\n",
    "fin_cols = ['Savings Of Line','Amended Total Cost Of Line','Total Cost Of Line','Exchange Rate']\n",
    "\n",
    "# Next replace '-' and NaN with 0, and convert to float for each column specified.\n",
    "for col in fin_cols:\n",
    "    df_filtered[col] = df_filtered[col].replace('-', 0).fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d490bb",
   "metadata": {},
   "source": [
    "### 3. Add New Columns \n",
    "These new columns will be crucial for the creation of graphs and other data analysis. The following columns will be added.\n",
    "1. 'Most Recent Action' - Calculated as the most recent date from all the date columns\n",
    "2. 'User Currently With' - Found by merging raw data with the standing data 'current-status' \n",
    "3. 'Status' - Found by merging raw data with the standing data 'current-status' \n",
    "4. 'Status (Updated)' - Found by merging raw data with the standing data 'current-status' \n",
    "5. 'Final Status' - Found by checking a nubmer of columns (including 'Status' above) to determine the final status.\n",
    "6. 'Line Item Savings IQD' - found as a multiple of the 'savings of line' column and the exchange rate\n",
    "7. 'Amended Line Item IQD' - found as a multiple of the 'Amended Total Cost Of Line' column and the exchange rate\n",
    "8. 'Original Line Item IQD' - found as a multiple of the 'Total Cost Of Line' column and the exchange rate\n",
    "9. 'Original Total Cost of SR' - Found as the total cost for each SR, mapped back onto each line\n",
    "10. 'Ministry' - Found by merging the Ministry/AU standing data onto the current data's AU column\n",
    "11. 'Analyst' - Found by merging the Ministry/Analyst data on the newly created ministry column\n",
    "12. 'days_since_last_action' - The difference in days between 'most recent action' and the analysis date\n",
    "13. 'tot_days_processing' - The difference in days between the most recent action and the date first submitted.\n",
    "14. 'analyst_days_processing' - the difference in days between the submission date and the analyst submitted date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f736b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'MOST RECENT ACTION' column\n",
    "\n",
    "#columns to include are all the columns from which the 'most recent action' could be. I.e. the most recent action\n",
    "# is the date that is most recent of the actions listed below.\n",
    "columns_to_include = [\n",
    "        'Date Submitted To Mofe','Approval Number Issued At','Ministry Input Id Issued At',\n",
    "        'Ministry Id Issued At','Ministry Diwan Reviewer Action Date','Ministry Diwan Decision Maker Action Date',\n",
    "        'Spending Team Action Date',\n",
    "        'Price Evaluation Action Date',\n",
    "        'Engineering Directorate Action Date','Publications Directorate Action Date',\n",
    "        'Director Of Spending Action Date','Dg Pa Action Date',\n",
    "        'Minister Of Finance Action Date','Com Action Date',\n",
    "        'Second Round Ministry Diwan Reviewer Action Date','Second Round Ministry Diwan Decision Maker Action Date',\n",
    "        'Second Round Spending Team Action Date','Second Round Director Of Spending Action Date',\n",
    "        'Second Round Dg Pa Action Date','Second Round Minister Of Finance Action Date',\n",
    "        'Second Round Com Action Date','Second Round Final Approval Date','Final Approval Date']\n",
    "\n",
    "# Determine the max of the included columns and write in as a new column to df_filtered\n",
    "df_filtered['Most Recent Action'] = df_filtered[columns_to_include].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9adcd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'User Currently With', 'Status', 'Status [Updated]' Columns\n",
    "\n",
    "# First ensure that all characters in the 'current state' columns of each dataframe are all uppercase, to ensure\n",
    "# matches when merging\n",
    "current_status['Current State'] = current_status['Current State'].str.upper()\n",
    "df_filtered['Current State'] = df_filtered['Current State'].str.upper()\n",
    "\n",
    "# Merge standing data 'standing-data-current-status and df_filtered to get the status columns\n",
    "df_filtered = pd.merge(df_filtered, current_status,how='left', on='Current State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1caf788",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'FINAL STATUS' column\n",
    "\n",
    "# First we define the function that determines what the status of each row.\n",
    "def final_status(row):\n",
    "    if row['Current State'] == \"REVOKED\" and row['Date Submitted To Mofe'] == pd.NaT:\n",
    "        return \"Not Submitted\"\n",
    "    \n",
    "    elif row['Current State'] == \"REVOKED\" and row['Final Approval Date'] != pd.NaT:\n",
    "        if row['Minister Of Finance Action'] == \"Approved By Minister Of Finance\" or row['Minister Of Finance Action'] == \"Amended and Approved By Minister Of Finance\" or  row['Minister Of Finance Action'] == \"Pending Tender\":\n",
    "            return \"Revoked After Approval\"\n",
    "        \n",
    "        elif row['Com Action'] == \"Approved By Council Of Ministers\" or row['Com Action'] == \"Amended And Approved By Council Of Ministers\" or row['Com Action'] == \"Pending Tender By Council Of Ministers\":\n",
    "            return \"Revoked After Approval\"\n",
    "        \n",
    "        elif row['Minister Of Finance Action'] == \"Rejected By Minister Of Finance\" or row['Com Action'] == \"Rejected By Council Of Ministers\":\n",
    "\n",
    "            return \"Revoked After Rejection\"\n",
    "        \n",
    "    elif row['Status'] == 'In process':\n",
    "        return 'In Process'\n",
    "    \n",
    "    elif row['Status'] == 'Not submitted':\n",
    "        return 'Not Submitted'\n",
    "    \n",
    "    elif row['Status'] == 'Revoked':\n",
    "        return 'Revoked'\n",
    "    \n",
    "    elif row['Status'] == 'Rejected':\n",
    "        return 'Rejected'\n",
    "    \n",
    "    elif row['Status'] == 'Approved':\n",
    "        if row['Total Sr Savings'] == 0:\n",
    "            return 'Approved'\n",
    "        else:\n",
    "            return 'Amended'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Once the function is defined we apply it row-wise to df_filtered\n",
    "df_filtered['Final Status'] = df_filtered.apply(final_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5aec482",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'Line Item Savings IQD', 'Amended Line Item IQD', 'Original Line Item IQD' columns\n",
    "\n",
    "# These columns can all be calculated as one line functions, as they are equal to df_filtered columns\n",
    "# multiplied by the equivalent entry in the 'exchange rate' column.\n",
    "\n",
    "### ADD 'LINE ITEM SAVINGS IQD'\n",
    "df_filtered['Line Item Savings IQD'] = df_filtered.apply(lambda row:\n",
    "                                                         row['Exchange Rate'] * row['Savings Of Line'],\n",
    "                                                         axis=1)\n",
    "### ADD 'Amended Line Item IQD'\n",
    "df_filtered['Amended Line Item IQD'] = df_filtered.apply(lambda row:\n",
    "                                                         row['Exchange Rate'] * row['Amended Total Cost Of Line'],\n",
    "                                                         axis=1)\n",
    "### Add 'Original Line Item IQD'\n",
    "df_filtered['Original Line Item IQD'] = df_filtered.apply(lambda row:\n",
    "                                                          row['Exchange Rate'] * row['Total Cost Of Line'],\n",
    "                                                          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a0946aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original Total Cost of SR' Column\n",
    "\n",
    "# Group the rows of the DataFrame by the values in 'Srid',\n",
    "# and calculate the sum of 'Original Line Item IQD' for each group\n",
    "sum_original = df_filtered.groupby('Srid')['Original Line Item IQD'].sum()\n",
    "\n",
    "# Create a new column 'Original Total Cost of SR' with the calculated values, mapped onto the relevant SRIDs\n",
    "df_filtered['Original Total Cost of SR'] = df_filtered['Srid'].map(sum_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "200eccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'Ministry'\n",
    "\n",
    "## Formed by merging au/ministry standing data with df_filtered on 'Entity' column (which contains AU names)\n",
    "df_filtered = pd.merge(df_filtered, au_ministry_data,how='left', on='Entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28e5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'Analyst'\n",
    "\n",
    "### Formed by merging au/ministry data with df_filtered on 'ministry' column\n",
    "df_filtered = pd.merge(df_filtered, ministry_analyst_data,how='left', on='Ministry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28024a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'days_since_last_action' column, calculated as the difference between the analysis date\n",
    "# and the most recent action\n",
    "df_filtered['days_since_last_action'] = df_filtered.apply(lambda row:\n",
    "                                                          (analysis_date - row['Most Recent Action']).days,\n",
    "                                                          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908790f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the 'tot_days_processing' column\n",
    "\n",
    "# Define a function to calculate the total processing time. This uses the 'workdays' package's 'networkdays'\n",
    "# and the KRG holidays standing data\n",
    "def tot_processing_time(row):\n",
    "    if pd.isna(row['Date Submitted To Mofe']) or pd.isna(row['Most Recent Action']):\n",
    "        days_processing = -1\n",
    "    elif row['Final Status'] == 'In Process':\n",
    "        days_processing = workdays.networkdays(row['Date Submitted To Mofe'], analysis_date,\n",
    "                                               holiday_dates)\n",
    "    else:\n",
    "        days_processing = workdays.networkdays(row['Date Submitted To Mofe'],row['Most Recent Action'],\n",
    "                                              holiday_dates)\n",
    "    return days_processing\n",
    "\n",
    "# Apply function rows-wise\n",
    "df_filtered['tot_days_processing'] = df_filtered.apply(tot_processing_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29bc3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the 'analyst_days_processing' column\n",
    "\n",
    "# Define a function to calculate the analyst processing time\n",
    "def analyst_processing_time(row):\n",
    "    if pd.isna(row['Date Submitted To Mofe']) or pd.isna(row['Spending Team Action Date']):\n",
    "        days_processing = 0\n",
    "    elif row['Final Status'] == 'In Process':\n",
    "        days_processing = workdays.networkdays(row['Date Submitted To Mofe'], analysis_date,\n",
    "                                              holiday_dates)\n",
    "    else:\n",
    "        days_processing = workdays.networkdays(row['Date Submitted To Mofe'],row['Spending Team Action Date'],\n",
    "                                              holiday_dates)\n",
    "    return days_processing\n",
    "\n",
    "# Apply function rows-wise\n",
    "df_filtered['analyst_days_processing'] = df_filtered.apply(analyst_processing_time, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c17706f",
   "metadata": {},
   "source": [
    "### 5. Generate output dataframe and export output\n",
    "\n",
    "We filter out the remaining columns which are not necessary for the production of graphs and charts (they were necessary before to create the additional columns). Finally we export the dataframe as a csv file so that it can be used in google sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a8dda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the columns we wish to keep\n",
    "output_cols = ['Srid', 'Date Submitted To Mofe', 'Account Code', 'Most Recent Action',\n",
    "       'User Currently With', 'Final Status','Line Item Savings IQD', 'Amended Line Item IQD',\n",
    "       'Original Line Item IQD', 'Original Total Cost of SR', 'Ministry',\n",
    "       'Analyst', 'days_since_last_action', 'tot_days_processing',\n",
    "       'analyst_days_processing']\n",
    "\n",
    "# Filter the dataframe on these columns and write to a new dataframe, df_final\n",
    "df_final = df_filtered[output_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343025a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You will need to write in your own path to find the data in your own machine.\n",
    "df_final.to_csv(root_path + r'/processed-data/srm-processed-data/' + \n",
    "                analysis_date.strftime(\"%y%m%d\") +r'-srm-data.csv',\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c80396b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srid</th>\n",
       "      <th>Date Submitted To Mofe</th>\n",
       "      <th>Account Code</th>\n",
       "      <th>Most Recent Action</th>\n",
       "      <th>User Currently With</th>\n",
       "      <th>Final Status</th>\n",
       "      <th>Line Item Savings IQD</th>\n",
       "      <th>Amended Line Item IQD</th>\n",
       "      <th>Original Line Item IQD</th>\n",
       "      <th>Original Total Cost of SR</th>\n",
       "      <th>Ministry</th>\n",
       "      <th>Analyst</th>\n",
       "      <th>days_since_last_action</th>\n",
       "      <th>tot_days_processing</th>\n",
       "      <th>analyst_days_processing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRID-1</td>\n",
       "      <td>2020-07-20 22:29:00</td>\n",
       "      <td>2-01-02-09-02-00</td>\n",
       "      <td>2020-09-20 13:26:00</td>\n",
       "      <td>Ministry - Rejected</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341000000.0</td>\n",
       "      <td>341000000.0</td>\n",
       "      <td>806000000.0</td>\n",
       "      <td>MOTAC</td>\n",
       "      <td>Helen</td>\n",
       "      <td>891.0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRID-1</td>\n",
       "      <td>2020-07-20 22:29:00</td>\n",
       "      <td>2-01-04-07-00-00</td>\n",
       "      <td>2020-09-20 13:26:00</td>\n",
       "      <td>Ministry - Rejected</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62000000.0</td>\n",
       "      <td>62000000.0</td>\n",
       "      <td>806000000.0</td>\n",
       "      <td>MOTAC</td>\n",
       "      <td>Helen</td>\n",
       "      <td>891.0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRID-1</td>\n",
       "      <td>2020-07-20 22:29:00</td>\n",
       "      <td>2-01-03-08-02-00</td>\n",
       "      <td>2020-09-20 13:26:00</td>\n",
       "      <td>Ministry - Rejected</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155000000.0</td>\n",
       "      <td>155000000.0</td>\n",
       "      <td>806000000.0</td>\n",
       "      <td>MOTAC</td>\n",
       "      <td>Helen</td>\n",
       "      <td>891.0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRID-1</td>\n",
       "      <td>2020-07-20 22:29:00</td>\n",
       "      <td>2-01-03-08-02-00</td>\n",
       "      <td>2020-09-20 13:26:00</td>\n",
       "      <td>Ministry - Rejected</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31000000.0</td>\n",
       "      <td>31000000.0</td>\n",
       "      <td>806000000.0</td>\n",
       "      <td>MOTAC</td>\n",
       "      <td>Helen</td>\n",
       "      <td>891.0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRID-1</td>\n",
       "      <td>2020-07-20 22:29:00</td>\n",
       "      <td>2-01-03-08-02-00</td>\n",
       "      <td>2020-09-20 13:26:00</td>\n",
       "      <td>Ministry - Rejected</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217000000.0</td>\n",
       "      <td>217000000.0</td>\n",
       "      <td>806000000.0</td>\n",
       "      <td>MOTAC</td>\n",
       "      <td>Helen</td>\n",
       "      <td>891.0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Srid Date Submitted To Mofe      Account Code  Most Recent Action  \\\n",
       "0  SRID-1    2020-07-20 22:29:00  2-01-02-09-02-00 2020-09-20 13:26:00   \n",
       "1  SRID-1    2020-07-20 22:29:00  2-01-04-07-00-00 2020-09-20 13:26:00   \n",
       "2  SRID-1    2020-07-20 22:29:00  2-01-03-08-02-00 2020-09-20 13:26:00   \n",
       "3  SRID-1    2020-07-20 22:29:00  2-01-03-08-02-00 2020-09-20 13:26:00   \n",
       "4  SRID-1    2020-07-20 22:29:00  2-01-03-08-02-00 2020-09-20 13:26:00   \n",
       "\n",
       "   User Currently With Final Status  Line Item Savings IQD  \\\n",
       "0  Ministry - Rejected     Rejected                    0.0   \n",
       "1  Ministry - Rejected     Rejected                    0.0   \n",
       "2  Ministry - Rejected     Rejected                    0.0   \n",
       "3  Ministry - Rejected     Rejected                    0.0   \n",
       "4  Ministry - Rejected     Rejected                    0.0   \n",
       "\n",
       "   Amended Line Item IQD  Original Line Item IQD  Original Total Cost of SR  \\\n",
       "0            341000000.0             341000000.0                806000000.0   \n",
       "1             62000000.0              62000000.0                806000000.0   \n",
       "2            155000000.0             155000000.0                806000000.0   \n",
       "3             31000000.0              31000000.0                806000000.0   \n",
       "4            217000000.0             217000000.0                806000000.0   \n",
       "\n",
       "  Ministry Analyst  days_since_last_action  tot_days_processing  \\\n",
       "0    MOTAC   Helen                   891.0                   41   \n",
       "1    MOTAC   Helen                   891.0                   41   \n",
       "2    MOTAC   Helen                   891.0                   41   \n",
       "3    MOTAC   Helen                   891.0                   41   \n",
       "4    MOTAC   Helen                   891.0                   41   \n",
       "\n",
       "   analyst_days_processing  \n",
       "0                        2  \n",
       "1                        2  \n",
       "2                        2  \n",
       "3                        2  \n",
       "4                        2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
